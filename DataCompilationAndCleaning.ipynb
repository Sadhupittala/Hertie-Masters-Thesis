{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01348dd9",
   "metadata": {},
   "source": [
    "In this notebook we will be creating granular datasets around meme dates from out bulk datasets (twitter and FEC). The FEC data needs to be cleaned still, but not much needs to be done besides parsing the date. \n",
    "\n",
    "Our end df's will be grouped by date, daily by whatever our 'dependent' variable is, either polarity (tweets) or individual donation (FEC). We want a csv for each Meme, in total there will be 8 (4 for tweets and 4 for FEC). They should be 1 month before peak and 1 month after peak.\n",
    "\n",
    "### Meme dates:\n",
    "Bernie: \n",
    "- Bird On Podium: april 2, 2016\n",
    "- Feel the bern: Feb 7-13 2016\n",
    "##### need to do\n",
    "- Feel the bern - April 10th now\n",
    "- Barnie Sandlers - January 17th\n",
    "\n",
    "Cruz:\n",
    "- Zodiac Killer: feb 28 2016\n",
    "- Zodiac Killer 2: May 1 2016\n",
    "\n",
    "##### need to do\n",
    "ted cruz look alike: April 30th\n",
    "\n",
    "\n",
    "FEC:\n",
    "- Grouped daily for sum donations.\n",
    "\n",
    "Tweets:\n",
    "- Grouped daily, average polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ffca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b236c42",
   "metadata": {},
   "source": [
    "## Tweets First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8960d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie = pd.concat([pd.read_csv(f) for f in ['bern2015-02-20.csv', 'bernie-2015-03-23T00:00:00+01:00.csv', 'bernie-2016-12-01T00:00:00+01:00.csv']])\n",
    "cruz = pd.read_csv(\"cruz-2016-12-01T00:00:00+01:00.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccf4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date):\n",
    "    year_month_day = date.split('T')[0].split('-')\n",
    "    year = int(year_month_day[0])\n",
    "    month = int(year_month_day[1])\n",
    "    day = int(year_month_day[2])\n",
    "    return datetime(year, month, day)\n",
    "\n",
    "def get_sentiment(text:str):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def clean_data(df: pd.DataFrame):\n",
    "    df = df.drop_duplicates(subset='id', keep='first')\n",
    "    \n",
    "    # format to datetime\n",
    "    df['created_at'] = df['created_at'].apply(format_date)\n",
    "    df['polarity'] = df['text'].apply(get_sentiment)\n",
    "        \n",
    "    dfg = df.groupby('created_at').mean('polarity')\n",
    "    \n",
    "    \n",
    "    return df, dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6e05bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/1608257482.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['created_at'] = df['created_at'].apply(format_date)\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/1608257482.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['polarity'] = df['text'].apply(get_sentiment)\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/1608257482.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['created_at'] = df['created_at'].apply(format_date)\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/1608257482.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['polarity'] = df['text'].apply(get_sentiment)\n"
     ]
    }
   ],
   "source": [
    "cruz, cruz_grouped = clean_data(cruz)\n",
    "bernie, bernie_grouped = clean_data(bernie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a466f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie_grouped = bernie_grouped.reset_index()\n",
    "cruz_grouped = cruz_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df20ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_meme(date, meme_date):\n",
    "    if date >= meme_date:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def create_meme_df(df: pd.DataFrame, meme_peak_date: datetime, date_column: str = 'created_at'):\n",
    "    begin = meme_peak_date - relativedelta(months=1)\n",
    "    end = meme_peak_date + relativedelta(months=1)\n",
    "    \n",
    "    meme_df = df[(df[date_column] >= begin) & (df[date_column]<=end)]\n",
    "    \n",
    "    # create variable that is 1 after meme peak date\n",
    "    meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
    "    \n",
    "    return meme_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec03b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernie Sanders Meme dates\n",
    "bird_on_podium_date = datetime(2016,4,2)\n",
    "feel_bern_date = datetime(2016,4,10)\n",
    "barnie_sandlers = datetime(2016,1,17)\n",
    "\n",
    "# Ted Cruz meme dates\n",
    "zodiac_1_date = datetime(2016, 2,28)\n",
    "zodiac_2_date = datetime(2016,5,1)\n",
    "look_alike=datetime(2016,4,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf28542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n"
     ]
    }
   ],
   "source": [
    "# bernie's meme dfs\n",
    "b_o_p_df = create_meme_df(bernie_grouped, bird_on_podium_date)\n",
    "feel_the_bern_df = create_meme_df(bernie_grouped, feel_bern_date)\n",
    "barnie_sandlers_df = create_meme_df(bernie_grouped, barnie_sandlers)\n",
    "# cruz's meme dfs\n",
    "zodiac_1_df = create_meme_df(cruz_grouped, zodiac_1_date)\n",
    "zodiac_2_df = create_meme_df(cruz_grouped, zodiac_2_date)\n",
    "look_alike_df = create_meme_df(cruz_grouped, look_alike)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e3842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_o_p_df.to_csv(\"data/twitter_bird_on_podium.csv\")\n",
    "feel_the_bern_df.to_csv(\"data/twitter_feel_the_bern.csv\")\n",
    "barnie_sandlers_df.to_csv(\"data/twitter_barnie_sandlers.csv\")\n",
    "zodiac_1_df.to_csv(\"data/twitter_zodaic_killer_1.csv\")\n",
    "zodiac_2_df.to_csv(\"data/twitter_zodiac_killer_2.csv\")\n",
    "look_alike_df.to_csv(\"data/twitter_look_alike.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937cab75",
   "metadata": {},
   "source": [
    "### FEC data Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0653bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/4000196023.py:1: DtypeWarning: Columns (10,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bernie_fec = pd.read_csv(\"bernie-2015-2016-FEC.csv\")\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/4000196023.py:2: DtypeWarning: Columns (5,10,15,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cruz_fec = pd.read_csv(\"cruz-2015-2016-FEC.csv\")\n"
     ]
    }
   ],
   "source": [
    "bernie_fec = pd.read_csv(\"bernie-2015-2016-FEC.csv\")\n",
    "cruz_fec = pd.read_csv(\"cruz-2015-2016-FEC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771f726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDate(date: float):\n",
    "    \"\"\"parse date from the float number in original dataset\"\"\"\n",
    "    date_num_str = str(int(date))\n",
    "    year = int(date_num_str[-4:])\n",
    "    day = int(date_num_str[-6:-4])\n",
    "    month = int(date_num_str[-8:-6])\n",
    "    \n",
    "    return datetime(year, month, day)\n",
    "\n",
    "def clean_fec_data(df: pd.DataFrame):\n",
    "    df['TRANSACTION_DT']=df['TRANSACTION_DT'].apply(parseDate)\n",
    "    dg = df[['TRANSACTION_DT', 'TRANSACTION_AMT']]\n",
    "\n",
    "    dg = dg.groupby('TRANSACTION_DT').sum('TRANSACTION_AMT')\n",
    "    dg = dg.reset_index()\n",
    "    \n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea6f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie_fec_grouped = clean_fec_data(bernie_fec)\n",
    "cruz_fec_grouped = clean_fec_data(cruz_fec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efea4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2219568398.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n"
     ]
    }
   ],
   "source": [
    "date_column = \"TRANSACTION_DT\"\n",
    "# bernie's meme dfs\n",
    "b_o_p__fec_df = create_meme_df(bernie_fec_grouped, bird_on_podium_date, date_column)\n",
    "feel_the_bern_fec_df = create_meme_df(bernie_fec_grouped, feel_bern_date, date_column)\n",
    "barnie_sandlers_fec_df = create_meme_df(bernie_fec_grouped, barnie_sandlers, date_column)\n",
    "# cruz's meme dfs\n",
    "zodiac_1_fec_df = create_meme_df(cruz_fec_grouped, zodiac_1_date, date_column)\n",
    "zodiac_2_fec_df = create_meme_df(cruz_fec_grouped, zodiac_2_date, date_column)\n",
    "look_alike_fec_df = create_meme_df(cruz_fec_grouped, look_alike, date_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74c9f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_o_p__fec_df.to_csv(\"data/fec_bird_on_podium.csv\")\n",
    "feel_the_bern_fec_df.to_csv(\"data/fec_feel_the_bern.csv\")\n",
    "barnie_sandlers_fec_df.to_csv(\"data/fec_barnie_sandlers.csv\")\n",
    "zodiac_1_fec_df.to_csv(\"data/fec_zodaic_killer_1.csv\")\n",
    "zodiac_2_fec_df.to_csv(\"data/fec_zodiac_killer_2.csv\")\n",
    "look_alike_fec_df.to_csv(\"data/fec_look_alike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097c136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7857e1",
   "metadata": {},
   "source": [
    "# Tweet Volume extra credit\n",
    "\n",
    "Now we will make some meme datasets for tweet volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94f2846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie_volume = pd.read_csv(\"data/bernie-tweet-volume.csv\")\n",
    "cruz_volume = pd.read_csv(\"data/cruz-tweet-volume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af44a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie_volume['start'] = bernie_volume['start'].apply(format_date)\n",
    "cruz_volume['start'] = cruz_volume['start'].apply(format_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bee91d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-31T00:00:00.000Z</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>7764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-01T00:00:00.000Z</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>9084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-02T00:00:00.000Z</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>14352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-03T00:00:00.000Z</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>15841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-04T00:00:00.000Z</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>18762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2015-01-14T00:00:00.000Z</td>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2015-01-15T00:00:00.000Z</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>2015-01-16T00:00:00.000Z</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>1629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2015-01-17T00:00:00.000Z</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2015-01-18T00:00:00.000Z</td>\n",
       "      <td>2015-01-17</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          end      start  tweet_count\n",
       "0    2016-10-31T00:00:00.000Z 2016-10-30         7764\n",
       "1    2016-11-01T00:00:00.000Z 2016-10-31         9084\n",
       "2    2016-11-02T00:00:00.000Z 2016-11-01        14352\n",
       "3    2016-11-03T00:00:00.000Z 2016-11-02        15841\n",
       "4    2016-11-04T00:00:00.000Z 2016-11-03        18762\n",
       "..                        ...        ...          ...\n",
       "695  2015-01-14T00:00:00.000Z 2015-01-13         1477\n",
       "696  2015-01-15T00:00:00.000Z 2015-01-14         2122\n",
       "697  2015-01-16T00:00:00.000Z 2015-01-15         1629\n",
       "698  2015-01-17T00:00:00.000Z 2015-01-16         1286\n",
       "699  2015-01-18T00:00:00.000Z 2015-01-17          892\n",
       "\n",
       "[700 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernie_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad8634ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n",
      "/var/folders/kx/ff4_40hx5q993v5z30g97l3w0000gn/T/ipykernel_96413/2637655744.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meme_df['after_meme_peak'] = df[date_column].apply(lambda x: is_meme(x,meme_peak_date))\n"
     ]
    }
   ],
   "source": [
    "date_column = \"start\"\n",
    "\n",
    "b_o_p_volume_df = create_meme_df(bernie_volume, bird_on_podium_date, date_column)\n",
    "feel_the_bern_volume_df = create_meme_df(bernie_volume, feel_bern_date, date_column)\n",
    "barnie_sandlers_volume_df = create_meme_df(bernie_volume, barnie_sandlers, date_column)\n",
    "# cruz's meme dfs\n",
    "zodiac_1_volume_df = create_meme_df(cruz_volume, zodiac_1_date, date_column)\n",
    "zodiac_2_volume_df = create_meme_df(cruz_volume, zodiac_2_date, date_column)\n",
    "look_alike_volume_df = create_meme_df(cruz_volume, look_alike, date_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b8ab407",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_o_p_volume_df.to_csv(\"data/volume_bird_on_podium.csv\")\n",
    "feel_the_bern_volume_df.to_csv(\"data/volume_feel_the_bern.csv\") \n",
    "barnie_sandlers_volume_df.to_csv(\"data/volume_barnie_sandlers.csv\") \n",
    "# cruz's meme dfs\n",
    "zodiac_1_volume_df.to_csv(\"data/volume_zodiac_1.csv\") \n",
    "zodiac_2_volume_df.to_csv(\"data/volume_zodiac_2.csv\")\n",
    "look_alike_volume_df.to_csv(\"data/volume_look_alike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77e8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
